# mlp-data-intro

## Project Overview

This repository contains the academic paper data and code for "Tracking Civic Space in Developing Countries with a High-Quality Corpus of Domestic Media and Transformer Models". It hosts everything associated with the MLP (Machine Learning for Peace) data introduction paper. The dataset covers 65 developing countries across regions: Eastern Europe/Central Asia, MENA, Latin America & Caribbean, East Asia, Sub-Saharan Africa.

Current Overleaf Location: https://www.overleaf.com/9891685827jxbvnrshzxbw#683bc8

### Event Categories
- **Civic events**: 20 categories including arrest, censor, protest, activism, coup, etc.
  - **CR variables**: Subset of civic events that are considered civil rights related
- **RAI events**: 22 categories of international influence including arms transfers, diplomatic activities, economic aid

## Source Management
- **International sources**: 16 major outlets (BBC, Reuters, NYT, etc.)
- **Regional sources**: 12 regional outlets
- **Local sources**: Country-specific outlets
- Source entry/exit tracking in final dataset columns for composition change detection


## Key Architecture

### Data Structure
- **`data/0-civic-by-source/`** and **`data/0-rai-by-source-and-influencer/`**: Source-level data
  - `[countryname].csv`: Per-country data files
  - Variables with `Norm` suffix: Raw counts normalized by `article_total`, which counts the number of articles published about that country per country-month.
  - Variables with `_ncr` suffix: Non-politically relevant events filtered out
- **`data/1-civic-aggregate/`** and **`data/1-rai-aggregate/`**: Aggregated country-month data
  - `[countryname].csv`: Per-country data files
  - Variables with `Norm` suffix: Raw counts normalized by `article_total`, which counts the number of articles published about that country per country-month.
  - Variables with `_ncr` suffix: Non-politically relevant events filtered out
- **`data/final-counts/`**: Raw and normalized article counts by country-month
  - `full-data.rds` and `full-data.csv`: Complete dataset across all countries
- **`data/shocks/`**: Event detection algorithm results showing major jumps in reporting (event salience) 

### Source Coverage
`data/1-source_entries.rds` captures the temporal coverage patterns of local news sources across the full time series. Generated by the `update_source_entries()` function, it creates a date Ã— source matrix where each cell contains:
- **1** if the source published articles in that month (total article count > 0)  
- **0** if the source was inactive in that month

This binary activity matrix is essential for tracking source entry/exit patterns over time and understanding changes in media landscape composition that could affect trend interpretation in civic space monitoring. 

### Core Scripts
- **`build_data/build_data.R`**: Main data construction pipeline to generate contents of `/data/`
- **`build_data/constants.R`**: List of event categories, countries, local/regional/international sources
- **`build_data/mlp_functions.R`**: Custom functions for data extraction and aggregation

## Shock Detection

`Surge.py` is a python notebook with a data pipeline that is used to systematically call functions to fetch the data, train the model to predict future surges in civic space and store the results.This notebook contains function that fetches the folder containing the most recent datasets for each country from the `Data` folder. Following that,the train function performs data preprocessing and model training. The obtained predictions and other results are stored in the `Result` folder.

`data.py` is a python script with functions that help in preliminary data processing of the dataset for each country which involves dropping raw versions of varibales, removing highly correlated variables etc. It also contains a list of target variables for which the future forecasts are made. The functions from this file are called in the `call_train` function of the Surge_Pipeline.ipynb.

`training.py` is a python script with functions that convert the preprocessed data into training data and has the main train function.The model used here is the AdaBoostClassifier with GridSearchCV. The scoring metrics considered to judge the model's performance are f1 score, precision and recall.

### Result

This folder contains the predicted results from the model. The Result folder has subfolders which are named in the YYYY-MM-DD format with the date of when the model was run and the predictions were made. This folder again has other subfolders for storing predictions and metrics results. The `predictions` subfolder has the country wise predictions per lag stored in .csv files. The `metrics` subfolder consitst of the files that have the values of different metrics obtained from the model such as f1,precision,recall,etc. The `final_metrics` and `final_predictions` subfolders has the averaged results over a range of lag for all metrics and all predictions for all countries, respectively. The `inverse_query` subfolder has the inverse_query results stored country-wise for all lags.


## Common Development Tasks

### Data Processing
```r
# Run main data construction pipeline
source("build_data/build_data.R")

```

### Key R Libraries
Core dependencies include: `tidyverse`, `here`, `psych`, `gt`, `kableExtra`, `ggplot2`, `changepoint`


## Important Notes
- All countries have data through 2024-12-01
- Date folder overrides can be specified in `date_folder()` function
- Path configurations in `data_update.R` handle multiple user environments


## Analysis for Manuscript

### GPT Summarization

This folder contains GPT-powered event summarization tools for the MLP project:

- **`GPT code.ipynb`**: Jupyter notebook implementing automated event summarization using OpenAI's GPT models. The script processes civic events detected by the ML4P forecasting system, retrieving relevant news articles from MongoDB and generating human-readable summaries for each event category by country-month. Includes functions for country/source mapping, text preprocessing, and two-stage summarization (event listing + final synthesis).

- **`event_prompts.csv`**: Contains templated prompts for 20 different civic event types (arrest, protest, corruption, etc.) with both detailed and concise prompt variations. Each prompt guides GPT to extract, rank, and summarize the most significant events while filtering out irrelevant or misplaced content.

### geoparsing_test

This folder evaluates geographic location extraction performance comparing CLIFF and GPT-4 systems:

- **`GPT Geoparsing.py`**: Python script using OpenAI's GPT-4 to extract geographic locations from news articles. Processes article text to identify the most specific location mentioned and complete the administrative hierarchy (country, admin1, admin2 levels) based on global administrative division knowledge.

- **`Geoparsing_report.Rmd`**: R Markdown analysis comparing CLIFF vs GPT performance on geographic entity extraction from 250 Colombian news articles. Evaluates accuracy across different administrative levels, categorizes errors by type (ambiguity, hierarchical misclassification, context disambiguation), and provides comprehensive performance metrics.

- **`Geoparsing_GPT_CLIFF.xlsx`**: Dataset containing results from both CLIFF and GPT geoparsing systems with human-coded ground truth for validation.

